{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "from lasagne.init import *\n",
    "from lasagne.updates import *\n",
    "from lasagne.objectives import *\n",
    "from lasagne.nonlinearities import *\n",
    "import math\n",
    "sys.path.append(\"../../modules/\")\n",
    "import helper as hp\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an MLP on MNIST with one hidden layer, we have this many params:<br />\n",
    "$784h + h + 10h + 10$, where $h$ is the number of units in that layer.\n",
    "\n",
    "Now, if we have a regression MLP on MNIST, the network capacity will be:<br />\n",
    "$784m + m + 1h + 1$, where $m$ is the number of units in that particular layer.\n",
    "\n",
    "We would like to choose a regression MLP with similar capacity. We can do this by solving for $m$:\n",
    "\n",
    "$784h + h + 10h + 10 = 784m + m + m + 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$784h + h + 10h + 10 = 784h + h + hm + m + 1m + 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_m(h):\n",
    "    return (784.0*h + h + 10*h + 10 - 1) / 786.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set, valid_set, test_set = hp.load_mnist(\"../../data/mnist.pkl.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xt, yt = train_set\n",
    "Xv, yv = valid_set\n",
    "Xt, Xv = Xt.reshape(Xt.shape[0], -1), Xv.reshape(Xv.shape[0], -1)\n",
    "yt, yv = yt.astype(\"int32\"), yv.astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.125954198473282"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_m(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7960"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "784*10 + 10 + 10*10 + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7960.000000000001"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "784*10.125954198473282 + 10.125954198473282 + 10.125954198473282 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_net(X_train, y_train, X_valid, y_valid, net, num_epochs, batch_size, shuffle=True, regression=False):\n",
    "    k = 10\n",
    "    train_fn, loss_fn, predict_fn = \\\n",
    "        net[\"train_fn\"], net[\"loss_fn\"], net[\"predict_fn\"]\n",
    "    idxs = [x for x in range(0, X_train.shape[0])]\n",
    "    for epoch in range(0, num_epochs):\n",
    "        if shuffle:\n",
    "            random.shuffle(idxs)\n",
    "            X_train = X_train[idxs]\n",
    "            y_train = y_train[idxs]\n",
    "        b = 0\n",
    "        losses = []\n",
    "        while True:\n",
    "            if b*batch_size >= X_train.shape[0]:\n",
    "                break\n",
    "            this_loss = train_fn(\n",
    "                X_train[b*batch_size : (b+1)*batch_size], y_train[b*batch_size : (b+1)*batch_size])\n",
    "            losses.append(this_loss)\n",
    "            b += 1\n",
    "        valid_loss = loss_fn(X_valid, y_valid)\n",
    "        valid_preds = predict_fn(X_valid)\n",
    "        if not regression:\n",
    "            valid_acc = 1.0*np.sum( np.argmax(valid_preds,axis=1) == y_valid ) / y_valid.shape[0]\n",
    "            valid_kappa = hp.weighted_kappa( np.argmax(valid_preds,axis=1), y_valid, num_classes=k )\n",
    "        else:\n",
    "            valid_acc = 1.0*np.sum( np.round(valid_preds.flatten()) == y_valid ) / y_valid.shape[0]\n",
    "            valid_preds = valid_preds.flatten()\n",
    "            valid_preds = np.round(valid_preds)\n",
    "            valid_preds = np.clip(valid_preds, 0, k-1).astype(\"int32\")\n",
    "            valid_kappa = hp.weighted_kappa(valid_preds, y_valid, num_classes=k )\n",
    "        print np.mean(losses), valid_loss, valid_acc, valid_kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kappa_net(h):\n",
    "    l_in = InputLayer( (None, 784) )\n",
    "    l_dense = DenseLayer(l_in, num_units=h, nonlinearity=rectify)\n",
    "    l_out = DenseLayer(l_dense, num_units=10, nonlinearity=softmax)\n",
    "    X = T.fmatrix('X')\n",
    "    y = T.ivector('y')\n",
    "    loss = categorical_crossentropy( get_output(l_out, X), y ).mean()\n",
    "    params = get_all_params(l_out)\n",
    "    updates = nesterov_momentum(loss, params, 0.01, 0.9)\n",
    "    train_fn = theano.function([X, y], loss, updates=updates)\n",
    "    predict_fn = theano.function([X], get_output(l_out, X) )\n",
    "    loss_fn = theano.function([X, y], loss )\n",
    "    for layer in get_all_layers(l_out):\n",
    "        print layer, layer.output_shape\n",
    "    print \"num params: %i\" % count_params(l_out)\n",
    "    return {\n",
    "        \"l_out\": l_out,\n",
    "        \"loss_fn\": loss_fn,\n",
    "        \"predict_fn\": predict_fn,\n",
    "        \"train_fn\": train_fn\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regression_net(h):\n",
    "    l_in = InputLayer( (None, 784) )\n",
    "    l_dense = DenseLayer(l_in, num_units=int(math.ceil(find_m(h))), nonlinearity=rectify)\n",
    "    l_dense2 = DenseLayer(l_dense, num_units=50)\n",
    "    l_out = DenseLayer(l_dense2, num_units=1, nonlinearity=rectify)\n",
    "    X = T.fmatrix('X')\n",
    "    y = T.ivector('y')\n",
    "    loss = squared_error( get_output(l_out, X).flatten(), y ).mean()\n",
    "    params = get_all_params(l_out)\n",
    "    updates = nesterov_momentum(loss, params, 0.01, 0.9)\n",
    "    train_fn = theano.function([X, y], loss, updates=updates)\n",
    "    predict_fn = theano.function([X], get_output(l_out, X) )\n",
    "    loss_fn = theano.function([X, y], loss )\n",
    "    for layer in get_all_layers(l_out):\n",
    "        print layer, layer.output_shape\n",
    "    print \"num params: %i\" % count_params(l_out)\n",
    "    return {\n",
    "        \"l_out\": l_out,\n",
    "        \"loss_fn\": loss_fn,\n",
    "        \"predict_fn\": predict_fn,\n",
    "        \"train_fn\": train_fn\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<lasagne.layers.input.InputLayer object at 0x116ef6b10> (None, 784)\n",
      "<lasagne.layers.dense.DenseLayer object at 0x116ef6e50> (None, 100)\n",
      "<lasagne.layers.dense.DenseLayer object at 0x10db509d0> (None, 10)\n",
      "num params: 79510\n",
      "0.527547673256 0.281596790733 0.9204 0.914195806339\n",
      "0.275767977681 0.227222227246 0.9358 0.929149831255\n",
      "0.226221666204 0.193686448013 0.9473 0.943246645645\n",
      "0.194075181997 0.174644071854 0.9515 0.949400558054\n",
      "0.170752735327 0.158337847591 0.9563 0.952048127169\n",
      "0.152516940589 0.146896764836 0.9596 0.955028264402\n",
      "0.137903819275 0.137545285882 0.9617 0.958068272781\n",
      "0.125884998087 0.127995953336 0.9653 0.961882955465\n",
      "0.115659199156 0.122573221227 0.9672 0.96287212872\n",
      "0.107364979546 0.115932924497 0.9682 0.965002163947\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "net1 = kappa_net(h=100)\n",
    "train_net(Xt, yt, Xv, yv, net1, num_epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<lasagne.layers.input.InputLayer object at 0x116fa5410> (None, 784)\n",
      "<lasagne.layers.dense.DenseLayer object at 0x116fa5a90> (None, 102)\n",
      "<lasagne.layers.dense.DenseLayer object at 0x116fa58d0> (None, 50)\n",
      "<lasagne.layers.dense.DenseLayer object at 0x10df6b9d0> (None, 1)\n",
      "num params: 85271\n",
      "1.95547046366 0.864033297581 0.6657 0.941859224752\n",
      "0.794919867854 0.667761066021 0.7072 0.956595150239\n",
      "0.599707949842 0.595677632487 0.755 0.960501815188\n",
      "0.500449393926 0.564038435128 0.7831 0.964147328511\n",
      "0.422642527919 0.548872833469 0.8038 0.964828505383\n",
      "0.355411596305 0.524059937415 0.8106 0.966771357743\n",
      "0.321185620451 0.453460602907 0.8391 0.971873103402\n",
      "0.280818066905 0.471797070507 0.8382 0.970213328916\n",
      "0.257209942895 0.454267637244 0.8499 0.971819277842\n",
      "0.230514491097 0.446139490961 0.8482 0.972143150609\n",
      "0.209161169454 0.432824039682 0.8572 0.972866941029\n",
      "0.194637222607 0.42308851331 0.8708 0.973973393745\n",
      "0.180312535024 0.4662180237 0.8622 0.971412897637\n",
      "0.173164784005 0.415833710732 0.8673 0.974189925751\n",
      "0.155583849946 0.408119209643 0.876 0.975091572309\n",
      "0.143949108202 0.439234834811 0.8695 0.972902957409\n",
      "0.135697487073 0.411152049783 0.875 0.974168427971\n",
      "0.121628606793 0.402100944509 0.8848 0.975372185691\n",
      "0.111165312947 0.408443836958 0.8759 0.974092677801\n",
      "0.102856097557 0.404783546672 0.8895 0.974815936915\n",
      "0.103905309569 0.432383815981 0.8788 0.973500933423\n",
      "0.0962195144839 0.407412601353 0.8864 0.974942130027\n",
      "0.0886847456974 0.403645538197 0.889 0.975250701539\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-171-d3ae9da6d159>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnet2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregression_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-151-7517c7b682a8>\u001b[0m in \u001b[0;36mtrain_net\u001b[0;34m(X_train, y_train, X_valid, y_valid, net, num_epochs, batch_size, shuffle, regression)\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             this_loss = train_fn(\n\u001b[0;32m---> 16\u001b[0;31m                 X_train[b*batch_size : (b+1)*batch_size], y_train[b*batch_size : (b+1)*batch_size])\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/Theano-0.8.0.dev0-py2.7.egg/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/Theano-0.8.0.dev0-py2.7.egg/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/Theano-0.8.0.dev0-py2.7.egg/theano/tensor/basic.pyc\u001b[0m in \u001b[0;36mperform\u001b[0;34m(self, node, inp, out)\u001b[0m\n\u001b[1;32m   5430\u001b[0m         \u001b[0;31m# gives a numpy float object but we need to return a 0d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5431\u001b[0m         \u001b[0;31m# ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5432\u001b[0;31m         \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5434\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "net2 = regression_net(h=100)\n",
    "train_net(Xt, yt, Xv, yv, net2, num_epochs=100, batch_size=128, regression=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 4, ..., 7, 4, 8], dtype=int32)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.clip( np.round( net2[\"predict_fn\"](Xt).flatten().astype(\"int32\") ), 0, 9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 8, 6, ..., 5, 6, 8], dtype=int32)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 4])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.clip([-2,3,5], 0, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
