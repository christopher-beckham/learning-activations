{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "from theano import tensor as T\n",
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "from lasagne.nonlinearities import *\n",
    "from lasagne.objectives import *\n",
    "from lasagne.regularization import *\n",
    "from lasagne.random import get_rng\n",
    "from lasagne.updates import *\n",
    "from lasagne.init import *\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"../../modules/\")\n",
    "import helper as hp\n",
    "\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().magic(u'matplotlib inline')\n",
    "\n",
    "import os\n",
    "import cPickle as pickle\n",
    "\n",
    "from theano.tensor import TensorType\n",
    "\n",
    "from theano.ifelse import ifelse\n",
    "\n",
    "from time import time\n",
    "\n",
    "get_ipython().magic(u'load_ext rpy2.ipython')\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, valid_data, _ = hp.load_mnist(\"../../data/mnist.pkl.gz\")\n",
    "X_train, y_train = train_data\n",
    "X_valid, y_valid = valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = X_train.astype(\"float32\"), y_train.astype(\"int32\")\n",
    "X_valid, y_valid = X_valid.astype(\"float32\"), y_valid.astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_srng = T.shared_randomstreams.RandomStreams()\n",
    "\n",
    "def theano_shuffled(input):\n",
    "    n = input.shape[0]\n",
    "\n",
    "    shuffled = T.permute_row_elements(input.T, _srng.permutation(n=n)).T\n",
    "    return shuffled\n",
    "\n",
    "class FractionalPool2DLayer(Layer):\n",
    "    \"\"\"\n",
    "    Fractional pooling as described in http://arxiv.org/abs/1412.6071\n",
    "    Only the random overlapping mode is currently implemented.\n",
    "    \"\"\"\n",
    "    def __init__(self, incoming, ds, pool_function=T.max, **kwargs):\n",
    "        super(FractionalPool2DLayer, self).__init__(incoming, **kwargs)\n",
    "        if type(ds) is not tuple:\n",
    "            raise ValueError(\"ds must be a tuple\")\n",
    "        if (not 1 <= ds[0] <= 2) or (not 1 <= ds[1] <= 2):\n",
    "            raise ValueError(\"ds must be between 1 and 2\")\n",
    "        self.ds = ds  # a tuple\n",
    "        if len(self.input_shape) != 4:\n",
    "            raise ValueError(\"Only bc01 currently supported\")\n",
    "        self.pool_function = pool_function\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        output_shape = list(input_shape) # copy / convert to mutable list\n",
    "        output_shape[2] = int(np.ceil(float(output_shape[2]) / self.ds[0]))\n",
    "        output_shape[3] = int(np.ceil(float(output_shape[3]) / self.ds[1]))\n",
    "\n",
    "        return tuple(output_shape)\n",
    "\n",
    "    def get_output_for(self, input, **kwargs):\n",
    "        _, _, n_in0, n_in1 = self.input_shape\n",
    "        _, _, n_out0, n_out1 = self.output_shape\n",
    "\n",
    "        # Variable stride across the input creates fractional reduction\n",
    "        a = theano.shared(\n",
    "            np.array([2] * (n_in0 - n_out0) + [1] * (2 * n_out0 - n_in0)))\n",
    "        b = theano.shared(\n",
    "            np.array([2] * (n_in1 - n_out1) + [1] * (2 * n_out1 - n_in1)))\n",
    "\n",
    "        # Randomize the input strides\n",
    "        a = theano_shuffled(a)\n",
    "        b = theano_shuffled(b)\n",
    "\n",
    "        # Convert to input positions, starting at 0\n",
    "        a = T.concatenate(([0], a[:-1]))\n",
    "        b = T.concatenate(([0], b[:-1]))\n",
    "        a = T.cumsum(a)\n",
    "        b = T.cumsum(b)\n",
    "\n",
    "        # Positions of the other corners\n",
    "        c = T.clip(a + 1, 0, n_in0 - 1)\n",
    "        d = T.clip(b + 1, 0, n_in1 - 1)\n",
    "\n",
    "        # Index the four positions in the pooling window and stack them\n",
    "        temp = T.stack(input[:, :, a, :][:, :, :, b],\n",
    "                       input[:, :, c, :][:, :, :, b],\n",
    "                       input[:, :, a, :][:, :, :, d],\n",
    "                       input[:, :, c, :][:, :, :, d])\n",
    "\n",
    "        return self.pool_function(temp, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fractional_net():\n",
    "    l_in = InputLayer( (None, 1, 28, 28) )\n",
    "    l_conv1 = Conv2DLayer(l_in, num_filters=16, filter_size=3)\n",
    "    l_mp1 = FractionalPool2DLayer(l_conv1, ds=(1.5,1.5))\n",
    "    l_conv2 = Conv2DLayer(l_mp1, num_filters=32, filter_size=3)\n",
    "    l_mp2 = FractionalPool2DLayer(l_conv2, ds=(1.5,1.5))\n",
    "    l_conv3 = Conv2DLayer(l_mp2, num_filters=40, filter_size=3)\n",
    "    l_mp3 = FractionalPool2DLayer(l_conv3, ds=(1.5,1.5))\n",
    "    l_conv4 = Conv2DLayer(l_mp3, num_filters=48, filter_size=3)\n",
    "    l_mp3 = FractionalPool2DLayer(l_conv4, ds=(1.5,1.5))\n",
    "    l_dense = DenseLayer(l_conv4, num_units=10, nonlinearity=softmax)\n",
    "    return l_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normal_net():\n",
    "    l_in = InputLayer( (None, 1, 28, 28) )\n",
    "    l_conv1 = Conv2DLayer(l_in, num_filters=32, filter_size=4)\n",
    "    l_mp1 = MaxPool2DLayer(l_conv1, pool_size=(2,2))\n",
    "    l_conv2 = Conv2DLayer(l_mp1, num_filters=48, filter_size=3)\n",
    "    l_mp2 = MaxPool2DLayer(l_conv2, pool_size=(2,2))\n",
    "    l_conv3 = Conv2DLayer(l_mp2, num_filters=64, filter_size=3)\n",
    "    l_mp3 = MaxPool2DLayer(l_conv3, pool_size=(2,2))\n",
    "    l_dense = DenseLayer(l_mp3, num_units=10, nonlinearity=softmax)\n",
    "    return l_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = l_in.input_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<lasagne.layers.input.InputLayer object at 0x11b5edf50> (None, 1, 28, 28)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x11d294650> (None, 16, 26, 26)\n",
      "<__main__.FractionalPool2DLayer object at 0x11ceea890> (None, 16, 18, 18)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x11d295c90> (None, 32, 16, 16)\n",
      "<__main__.FractionalPool2DLayer object at 0x11d295910> (None, 32, 11, 11)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x11d295810> (None, 40, 9, 9)\n",
      "<__main__.FractionalPool2DLayer object at 0x10ec9cd10> (None, 40, 6, 6)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x11d295ad0> (None, 48, 4, 4)\n",
      "<lasagne.layers.dense.DenseLayer object at 0x11d295bd0> (None, 10)\n",
      "number of params: 41378\n"
     ]
    }
   ],
   "source": [
    "l_out = fractional_net()\n",
    "for layer in get_all_layers(l_out):\n",
    "    print layer, layer.output_shape\n",
    "print \"number of params:\", count_params(l_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<lasagne.layers.input.InputLayer object at 0x11b55d250> (None, 1, 28, 28)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x11d293f90> (None, 32, 25, 25)\n",
      "<lasagne.layers.pool.MaxPool2DLayer object at 0x11b55d990> (None, 32, 12, 12)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x11d293dd0> (None, 48, 10, 10)\n",
      "<lasagne.layers.pool.MaxPool2DLayer object at 0x11d293e90> (None, 48, 5, 5)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x11ceeae10> (None, 64, 3, 3)\n",
      "<lasagne.layers.pool.MaxPool2DLayer object at 0x10ece0910> (None, 64, 1, 1)\n",
      "<lasagne.layers.dense.DenseLayer object at 0x11ceea250> (None, 10)\n",
      "number of params: 42778\n"
     ]
    }
   ],
   "source": [
    "l_out = normal_net()\n",
    "for layer in get_all_layers(l_out):\n",
    "    print layer, layer.output_shape\n",
    "print \"number of params:\", count_params(l_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = T.tensor4('X')\n",
    "y = T.ivector('y')\n",
    "l_out = fractional_net()\n",
    "# ----\n",
    "net_out = get_output(l_out, X)\n",
    "loss = categorical_crossentropy(net_out, y).mean()\n",
    "params = get_all_params(l_out, trainable=True)\n",
    "grads = T.grad(loss, params)\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "updates = nesterov_momentum(grads, params, learning_rate=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_fn = theano.function([X,y], loss, updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.533836153266\n",
      "59.6200299263\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "bs = 32\n",
    "n_batches = X_train.shape[0] // bs\n",
    "\n",
    "print \"epochs\", \"time\"\n",
    "num_epochs=10\n",
    "for epoch in range(0, num_epochs):\n",
    "    losses=[]\n",
    "    for b in range(0, n_batches):\n",
    "        losses.append( train_fn(X_train[b*bs:(b+1)*bs], y_train[b*bs:(b+1)*bs]) )\n",
    "    print np.mean(losses), time()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
